# **Stream Processing Meets Machine Learning: An Apache Flink Workshop**  

### **Presented by:**  
**Tulika Bhatt** â€“ Senior Engineer at Netflix  

ðŸ“Œ **Event Link:**  
ðŸ”— [Join the Discussion](https://community.analyticsvidhya.com/c/datahour/stream-processing-meets-machine-learning-an-apache-flink-workshop)  

ðŸ“š **Resources:**  
ðŸ”— [Workshop Materials](https://www.analyticsvidhya.com/events/datahour/stream-processing-meets-machine-learning-an-apache-flink-workshop/)  

---

## **Checkpointing in Flink**  
âœ… **Periodic snapshots** of the application state  
âœ… Helps with **fault tolerance** and recovery  
âœ… Stores data in a **distributed file system**  

### **Savepoints**  
ðŸ”¹ Manual snapshots for application **upgrades and maintenance**  
ðŸ”¹ **Exactly-once** semantics  
ðŸ”¹ Handling **backpressure**  

---

## **Flink Execution Model**  
ðŸ”¹ **Components of Flink:**  
   - **Job Graph & DAG Operators** â€“ Describe computation (e.g., *map, filter, windows*).  
   - **JobManager (JM)** â€“ The master node responsible for job scheduling, checkpoint coordination, and failure recovery.  
   - **TaskManager (TM)** â€“ Worker nodes that execute tasks and provide resources for parallel execution.  
   - **Parallelism Level** â€“ Defines how many parallel instances are used at the task level.  

---

## **Flink Operators**  
Operators define how data is processed in a Flink pipeline.  

### **Types of Flink Operators:**  
ðŸ”¹ **Source Operators** â€“ Ingest data from Kafka, files, databases, etc.  
ðŸ”¹ **Transformation Operators** â€“ Process and manipulate data streams.  
ðŸ”¹ **Sink Operators** â€“ Store or output results to external systems like Kafka, databases, or dashboards.  
ðŸ”¹ **Custom Operators** â€“ Extend Flinkâ€™s capabilities with User-Defined Functions (UDFs).  

ðŸ’¡ *You can create custom operators if the built-in transformations do not meet your needs.*  

